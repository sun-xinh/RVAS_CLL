{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/html": "    <style>\n        .bk-notebook-logo {\n            display: block;\n            width: 20px;\n            height: 20px;\n            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n        }\n    </style>\n    <div>\n        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n        <span id=\"aba53107-f66e-4180-89d9-6d4eb140dad0\">Loading BokehJS ...</span>\n    </div>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"aba53107-f66e-4180-89d9-6d4eb140dad0\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"aba53107-f66e-4180-89d9-6d4eb140dad0\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"aba53107-f66e-4180-89d9-6d4eb140dad0\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"aba53107-f66e-4180-89d9-6d4eb140dad0\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/06/10 17:51:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "Running on Apache Spark version 3.3.4\n",
      "SparkUI available at http://192.168.0.16:4040\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.130-bea04d9c79b5\n",
      "LOGGING: writing to /Users/benoppenheimer/Dropbox (Partners HealthCare)/ancestry_analysis_2/code/hail-20240610-1751-0.2.130-bea04d9c79b5.log\n"
     ]
    }
   ],
   "source": [
    "import hail as hl\n",
    "hl.init()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set-up Functions and Variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "all_sample_list = set(np.loadtxt(\"../ashkenazi_data/ref_samples.txt\", dtype=str))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "  Sample_Name Gender Ancestry\n0      SA1004      F  Khomani\n1       SA063      F  Khomani\n2       SA010      F  Khomani\n3       SA064      M  Khomani\n4       SA073      F  Khomani",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sample_Name</th>\n      <th>Gender</th>\n      <th>Ancestry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SA1004</td>\n      <td>F</td>\n      <td>Khomani</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SA063</td>\n      <td>F</td>\n      <td>Khomani</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SA010</td>\n      <td>F</td>\n      <td>Khomani</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SA064</td>\n      <td>M</td>\n      <td>Khomani</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SA073</td>\n      <td>F</td>\n      <td>Khomani</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reich_samples = []\n",
    "with open(\"../ashkenazi_data/EuropeFullyPublic/original_eigenstrat/vdata.ind\") as f:\n",
    "    for line in f.readlines():\n",
    "        sample = line.strip().split()\n",
    "        reich_samples.append(sample)\n",
    "reich_df = pd.DataFrame(data=reich_samples, columns=[\"Sample_Name\", \"Gender\", \"Ancestry\"])\n",
    "reich_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   0       1  2  3  4  5\n0  1  SA1004  0  0  2  1\n1  2   SA063  0  0  2  1\n2  3   SA010  0  0  2  1\n3  4   SA064  0  0  1  1\n4  5   SA073  0  0  2  1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>SA1004</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>SA063</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>SA010</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>SA064</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>SA073</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reich_samples = []\n",
    "with open(\"../ashkenazi_data/EuropeFullyPublic/convertf_plink/vdata.fam\") as f:\n",
    "    for line in f.readlines():\n",
    "        sample = line.strip().split()\n",
    "        reich_samples.append(sample)\n",
    "orginal_fam = pd.DataFrame(data=reich_samples)\n",
    "orginal_fam.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "orginal_fam.to_csv(\"../ashkenazi_data/EuropeFullyPublic/convertf_plink/vdata.fam\", sep=\" \", header=False, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w0/3_6gnh594j99k2l1f70tp2tm0000gn/T/ipykernel_3958/4225007770.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reich_samples_to_include.loc[:, \"plink_name\"] = (reich_samples_to_include.index + 1).astype(str) + \"\\t\" + \\\n"
     ]
    },
    {
     "data": {
      "text/plain": "           Sample_Name Gender       Ancestry              plink_name\n1633  AshkenaziJew5779      F  Ashkenazi_Jew  1634\\tAshkenaziJew5779\n1653  AshkenaziJew5782      M  Ashkenazi_Jew  1654\\tAshkenaziJew5782\n1797  AshkenaziJew5783      M  Ashkenazi_Jew  1798\\tAshkenaziJew5783\n1800  AshkenaziJew5704      F  Ashkenazi_Jew  1801\\tAshkenaziJew5704\n1807  AshkenaziJew5728      F  Ashkenazi_Jew  1808\\tAshkenaziJew5728\n1813  AshkenaziJew5790      M  Ashkenazi_Jew  1814\\tAshkenaziJew5790\n1905  AshkenaziJew5788      M  Ashkenazi_Jew  1906\\tAshkenaziJew5788",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sample_Name</th>\n      <th>Gender</th>\n      <th>Ancestry</th>\n      <th>plink_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1633</th>\n      <td>AshkenaziJew5779</td>\n      <td>F</td>\n      <td>Ashkenazi_Jew</td>\n      <td>1634\\tAshkenaziJew5779</td>\n    </tr>\n    <tr>\n      <th>1653</th>\n      <td>AshkenaziJew5782</td>\n      <td>M</td>\n      <td>Ashkenazi_Jew</td>\n      <td>1654\\tAshkenaziJew5782</td>\n    </tr>\n    <tr>\n      <th>1797</th>\n      <td>AshkenaziJew5783</td>\n      <td>M</td>\n      <td>Ashkenazi_Jew</td>\n      <td>1798\\tAshkenaziJew5783</td>\n    </tr>\n    <tr>\n      <th>1800</th>\n      <td>AshkenaziJew5704</td>\n      <td>F</td>\n      <td>Ashkenazi_Jew</td>\n      <td>1801\\tAshkenaziJew5704</td>\n    </tr>\n    <tr>\n      <th>1807</th>\n      <td>AshkenaziJew5728</td>\n      <td>F</td>\n      <td>Ashkenazi_Jew</td>\n      <td>1808\\tAshkenaziJew5728</td>\n    </tr>\n    <tr>\n      <th>1813</th>\n      <td>AshkenaziJew5790</td>\n      <td>M</td>\n      <td>Ashkenazi_Jew</td>\n      <td>1814\\tAshkenaziJew5790</td>\n    </tr>\n    <tr>\n      <th>1905</th>\n      <td>AshkenaziJew5788</td>\n      <td>M</td>\n      <td>Ashkenazi_Jew</td>\n      <td>1906\\tAshkenaziJew5788</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reich_samples_to_include = reich_df[reich_df.Ancestry.str.startswith(\"Ashkenazi\")]\n",
    "reich_samples_to_include.loc[:, \"plink_name\"] = (reich_samples_to_include.index + 1).astype(str) + \"\\t\" + \\\n",
    "                                                reich_samples_to_include.Sample_Name\n",
    "reich_samples_to_include"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reich_samples_to_include.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "reich_samples_to_include.Sample_Name.to_csv(\"../ashkenazi_data/EuropeFullyPublic/samples_to_include.txt\",\n",
    "                                            header=False, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Sample ID  Population Country / collected in Continent  chip\n0  EthiopiaAm50  Ethiopians               Ethiopia    Africa  660k\n1  EthiopiaAm52  Ethiopians               Ethiopia    Africa  660k\n2  EthiopiaAm58  Ethiopians               Ethiopia    Africa  660k\n3  EthiopiaAm59  Ethiopians               Ethiopia    Africa  660k\n4  EthiopiaAm76  Ethiopians               Ethiopia    Africa  660k",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sample ID</th>\n      <th>Population</th>\n      <th>Country / collected in</th>\n      <th>Continent</th>\n      <th>chip</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EthiopiaAm50</td>\n      <td>Ethiopians</td>\n      <td>Ethiopia</td>\n      <td>Africa</td>\n      <td>660k</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>EthiopiaAm52</td>\n      <td>Ethiopians</td>\n      <td>Ethiopia</td>\n      <td>Africa</td>\n      <td>660k</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>EthiopiaAm58</td>\n      <td>Ethiopians</td>\n      <td>Ethiopia</td>\n      <td>Africa</td>\n      <td>660k</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>EthiopiaAm59</td>\n      <td>Ethiopians</td>\n      <td>Ethiopia</td>\n      <td>Africa</td>\n      <td>660k</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>EthiopiaAm76</td>\n      <td>Ethiopians</td>\n      <td>Ethiopia</td>\n      <td>Africa</td>\n      <td>660k</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jew_samples = pd.read_excel(\"../ashkenazi_data/jew/Jew_paper_samples.xlsx\")\n",
    "jew_samples.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w0/3_6gnh594j99k2l1f70tp2tm0000gn/T/ipykernel_3958/2019007429.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  jew_samples_to_include.loc[:, \"plink_name\"] = jew_samples_to_include[\"Sample ID\"] + \" \" + \\\n"
     ]
    },
    {
     "data": {
      "text/plain": "        Sample ID      Population Country / collected in Continent  chip  \\\n180  ashkenazy10e  Ashkenazy_Jews                 Russia    Europe  610k   \n181  ashkenazy10w  Ashkenazy_Jews            Netherlands    Europe  610k   \n182   ashkenazy1e  Ashkenazy_Jews             Belorussia    Europe  610k   \n183   ashkenazy1w  Ashkenazy_Jews                Austria    Europe  610k   \n184   ashkenazy2e  Ashkenazy_Jews             Belorussia    Europe  610k   \n\n                    plink_name  \n180  ashkenazy10e ashkenazy10e  \n181  ashkenazy10w ashkenazy10w  \n182    ashkenazy1e ashkenazy1e  \n183    ashkenazy1w ashkenazy1w  \n184    ashkenazy2e ashkenazy2e  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sample ID</th>\n      <th>Population</th>\n      <th>Country / collected in</th>\n      <th>Continent</th>\n      <th>chip</th>\n      <th>plink_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>180</th>\n      <td>ashkenazy10e</td>\n      <td>Ashkenazy_Jews</td>\n      <td>Russia</td>\n      <td>Europe</td>\n      <td>610k</td>\n      <td>ashkenazy10e ashkenazy10e</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>ashkenazy10w</td>\n      <td>Ashkenazy_Jews</td>\n      <td>Netherlands</td>\n      <td>Europe</td>\n      <td>610k</td>\n      <td>ashkenazy10w ashkenazy10w</td>\n    </tr>\n    <tr>\n      <th>182</th>\n      <td>ashkenazy1e</td>\n      <td>Ashkenazy_Jews</td>\n      <td>Belorussia</td>\n      <td>Europe</td>\n      <td>610k</td>\n      <td>ashkenazy1e ashkenazy1e</td>\n    </tr>\n    <tr>\n      <th>183</th>\n      <td>ashkenazy1w</td>\n      <td>Ashkenazy_Jews</td>\n      <td>Austria</td>\n      <td>Europe</td>\n      <td>610k</td>\n      <td>ashkenazy1w ashkenazy1w</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>ashkenazy2e</td>\n      <td>Ashkenazy_Jews</td>\n      <td>Belorussia</td>\n      <td>Europe</td>\n      <td>610k</td>\n      <td>ashkenazy2e ashkenazy2e</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jew_samples_to_include = jew_samples[jew_samples.Population.str.startswith(\"Ashkenazy\")]\n",
    "jew_samples_to_include.loc[:, \"plink_name\"] = jew_samples_to_include[\"Sample ID\"] + \" \" + \\\n",
    "                                              jew_samples_to_include[\"Sample ID\"]\n",
    "jew_samples_to_include.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "21"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jew_samples_to_include.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jew_samples_to_include[\"Sample ID\"].isin(reich_samples_to_include.Sample_Name).any()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "jew_samples_to_include.plink_name.to_csv(\"../ashkenazi_data/jew/samples_to_include.txt\", header=False, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_samples_in_cohort(fam_file):\n",
    "    samples = dict()\n",
    "    with open(fam_file) as f:\n",
    "        for line in f.readlines():\n",
    "            split_line = line.split()\n",
    "            fam_id = split_line[0]\n",
    "            sample = split_line[1]\n",
    "            samples[sample] = fam_id\n",
    "    return samples\n",
    "\n",
    "def liftover_vcf_file(cohort):\n",
    "    input_vcf = cohort.get_suffix_bfile(\"filtered\") + \".vcf\"\n",
    "    mt = hl.import_vcf(input_vcf)\n",
    "    mt = mt.annotate_rows(new_locus=hl.liftover(mt.locus, 'GRCh38', include_strand=True), old_locus=mt.locus)\n",
    "\n",
    "    #save not_lifted vcf info\n",
    "    not_lifted_mt = mt.filter_rows(~hl.is_defined(mt.new_locus) | mt.new_locus.is_negative_strand)\n",
    "    not_lifted_vcf = cohort.get_suffix_bfile(\"not_lifted\") + \".vcf\"\n",
    "    hl.export_vcf(not_lifted_mt, not_lifted_vcf)\n",
    "\n",
    "    lifted_mt = mt.filter_rows(hl.is_defined(mt.new_locus) & ~mt.new_locus.is_negative_strand)\n",
    "    lifted_mt = lifted_mt.key_rows_by(locus=lifted_mt.new_locus.result, alleles=lifted_mt.alleles)\n",
    "    lifted_mt_filename = cohort.get_suffix_bfile(\"lifted_mt\") + \".vcf\"\n",
    "    hl.export_vcf(lifted_mt, lifted_mt_filename)\n",
    "\n",
    "\n",
    "class Cohort:\n",
    "\n",
    "    def __init__(self, original_bfile, is_bfile=True):\n",
    "\n",
    "        self.original_bfile = original_bfile\n",
    "        self.original_bfile_name = os.path.basename(self.original_bfile)\n",
    "\n",
    "        split_dir = self.original_bfile.split(\"/\")\n",
    "        self.dir = \"/\".join(split_dir[0:-2])\n",
    "\n",
    "\n",
    "    def get_suffix_bfile(self, suffix):\n",
    "        corrected_dir = self.dir + \"/\" + suffix\n",
    "\n",
    "        if not os.path.exists(corrected_dir):\n",
    "            os.mkdir(corrected_dir)\n",
    "\n",
    "        corrected_bfile = corrected_dir + \"/\" + self.original_bfile_name + \"_\" + suffix\n",
    "        return corrected_bfile"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "original_bfiles = [\"../ashkenazi_data/EuropeFullyPublic/convertf_plink/vdata\",\n",
    "                   \"../ashkenazi_data/jew/original_plink/jew_paper_data_dbSNP-b131_pos-b37_1KG_strand\"]\n",
    "cohorts = [Cohort(original_bfile) for original_bfile in original_bfiles]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cohort' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/w0/3_6gnh594j99k2l1f70tp2tm0000gn/T/ipykernel_3958/813250474.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mcohort\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moriginal_bfile\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'cohort' is not defined"
     ]
    }
   ],
   "source": [
    "cohort.original_bfile"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 17:51:22.459 Hail: INFO: Found 1963 samples in fam file.\n",
      "2024-06-10 17:51:22.459 Hail: INFO: Found 600841 variants in bim file.\n",
      "2024-06-10 17:51:23.446 Hail: INFO: Found 1963 samples in fam file.\n",
      "2024-06-10 17:51:23.446 Hail: INFO: Found 600841 variants in bim file.\n",
      "[Stage 0:==================================================>      (16 + 2) / 18]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original count: (600841, 1963)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 17:51:30.405 Hail: INFO: Found 1963 samples in fam file.\n",
      "2024-06-10 17:51:30.406 Hail: INFO: Found 600841 variants in bim file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count for Ashkenazi data (600841, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 17:51:37.878 Hail: INFO: Found 1963 samples in fam file.\n",
      "2024-06-10 17:51:37.878 Hail: INFO: Found 600841 variants in bim file.\n",
      "2024-06-10 17:52:04.986 Hail: INFO: wrote matrix table with 600841 rows and 6 columns in 18 partitions to ../ashkenazi_data/EuropeFullyPublic/filtered_mt.mt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 17:52:06.066 Hail: INFO: Found 466 samples in fam file.\n",
      "2024-06-10 17:52:06.067 Hail: INFO: Found 555737 variants in bim file.\n",
      "2024-06-10 17:52:08.388 Hail: INFO: Found 466 samples in fam file.\n",
      "2024-06-10 17:52:08.388 Hail: INFO: Found 555737 variants in bim file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original count: (555737, 466)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"RemoteBlock-temp-file-clean-thread\"\n",
      "Exception in thread \"idle-timeout-task\" Exception in thread \"refresh progress\" Exception in thread \"dispatcher-event-loop-1\" java.lang.OutOfMemoryError: Java heap space\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "Exception in thread \"Spark Context Cleaner\" java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.ContextCleaner$$Lambda$937/0x00000008008ad040.get$Lambda(Unknown Source)\n",
      "\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeStatic(DirectMethodHandle$Holder)\n",
      "\tat java.base/java.lang.invoke.LambdaForm$MH/0x0000000800061840.linkToTargetMethod(LambdaForm$MH)\n",
      "\tat org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195)\n",
      "\tat org.apache.spark.ContextCleaner$$Lambda$778/0x0000000800810440.apply$mcV$sp(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446)\n",
      "\tat org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189)\n",
      "\tat org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79)\n"
     ]
    },
    {
     "ename": "FatalError",
     "evalue": "OutOfMemoryError: Java heap space\n\nJava stack trace:\njava.lang.OutOfMemoryError: Java heap space\n\tat \n\n\n\nHail version: 0.2.130-bea04d9c79b5\nError summary: OutOfMemoryError: Java heap space",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFatalError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/w0/3_6gnh594j99k2l1f70tp2tm0000gn/T/ipykernel_3958/4032103384.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"original count:\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcount\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m     \u001B[0mmt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfilter_samples\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcohort\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"count for Ashkenazi data\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcount\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m     \u001B[0mmt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"{cohort.dir}/filtered_mt.mt\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moverwrite\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/lib/python3.9/site-packages/hail/matrixtable.py\u001B[0m in \u001B[0;36mcount\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2690\u001B[0m         \"\"\"\n\u001B[1;32m   2691\u001B[0m         \u001B[0mcount_ir\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mir\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mMatrixCount\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_mir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2692\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mEnv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcount_ir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2693\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2694\u001B[0m     @typecheck_method(\n",
      "\u001B[0;32m/opt/homebrew/lib/python3.9/site-packages/hail/backend/spark_backend.py\u001B[0m in \u001B[0;36mexecute\u001B[0;34m(self, ir, timed)\u001B[0m\n\u001B[1;32m    224\u001B[0m                     \u001B[0;32mraise\u001B[0m \u001B[0merr\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mfatal\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    225\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 226\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    227\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    228\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/lib/python3.9/site-packages/hail/backend/spark_backend.py\u001B[0m in \u001B[0;36mexecute\u001B[0;34m(self, ir, timed)\u001B[0m\n\u001B[1;32m    216\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mexecute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mir\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mBaseIR\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimed\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mbool\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    217\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 218\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimed\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    219\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_copy_log_on_error\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/lib/python3.9/site-packages/hail/backend/backend.py\u001B[0m in \u001B[0;36mexecute\u001B[0;34m(self, ir, timed)\u001B[0m\n\u001B[1;32m    188\u001B[0m             \u001B[0mresult\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_rpc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mActionTag\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEXECUTE\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpayload\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mFatalError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 190\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmaybe_user_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mir\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    191\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mir\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtyp\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mtvoid\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    192\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/lib/python3.9/site-packages/hail/backend/backend.py\u001B[0m in \u001B[0;36mexecute\u001B[0;34m(self, ir, timed)\u001B[0m\n\u001B[1;32m    186\u001B[0m         \u001B[0mpayload\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mExecutePayload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_render_ir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'{\"name\":\"StreamBufferSpec\"}'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimed\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    187\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 188\u001B[0;31m             \u001B[0mresult\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_rpc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mActionTag\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEXECUTE\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpayload\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    189\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mFatalError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    190\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmaybe_user_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mir\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/lib/python3.9/site-packages/hail/backend/py4j_backend.py\u001B[0m in \u001B[0;36m_rpc\u001B[0;34m(self, action, payload)\u001B[0m\n\u001B[1;32m    219\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mresp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatus_code\u001B[0m \u001B[0;34m>=\u001B[0m \u001B[0;36m400\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m             \u001B[0merror_json\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0morjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloads\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontent\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 221\u001B[0;31m             raise fatal_error_from_java_error_triplet(\n\u001B[0m\u001B[1;32m    222\u001B[0m                 \u001B[0merror_json\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'short'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merror_json\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'expanded'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merror_json\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'error_id'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    223\u001B[0m             )\n",
      "\u001B[0;31mFatalError\u001B[0m: OutOfMemoryError: Java heap space\n\nJava stack trace:\njava.lang.OutOfMemoryError: Java heap space\n\tat \n\n\n\nHail version: 0.2.130-bea04d9c79b5\nError summary: OutOfMemoryError: Java heap space"
     ]
    }
   ],
   "source": [
    "hg19_fasta = \"../../hg38_reference_data/Homo_sapiens_assembly19.fasta\"\n",
    "\n",
    "def filter_samples(mt, cohort):\n",
    "\n",
    "    samples_to_include_file = f\"{cohort.dir}/samples_to_include.txt\"\n",
    "    samples_to_include = set(pd.read_csv(samples_to_include_file).iloc[:, 0].to_list())\n",
    "\n",
    "    set_to_keep = hl.literal(samples_to_include)\n",
    "\n",
    "    mt = mt.filter_cols(set_to_keep.contains(mt['s']))\n",
    "    return mt\n",
    "\n",
    "for i, cohort in enumerate(cohorts):\n",
    "    print(i)\n",
    "    mt = hl.import_plink(bed=f\"{cohort.original_bfile}.bed\",\n",
    "                     bim=f\"{cohort.original_bfile}.bim\",\n",
    "                     fam=f\"{cohort.original_bfile}.fam\",\n",
    "                     reference_genome='GRCh37')\n",
    "    print(\"original count:\", mt.count())\n",
    "    mt = filter_samples(mt, cohort)\n",
    "    print(\"count for Ashkenazi data\", mt.count())\n",
    "    mt.write(f\"{cohort.dir}/filtered_mt.mt\", overwrite=True)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Liftover Bed Files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 14:46:58.933 Hail: INFO: Found 466 samples in fam file.\n",
      "2024-06-10 14:46:58.934 Hail: INFO: Found 555737 variants in bim file.\n",
      "2024-06-10 14:46:59.696 Hail: INFO: Found 466 samples in fam file.\n",
      "2024-06-10 14:46:59.696 Hail: INFO: Found 555737 variants in bim file.\n"
     ]
    },
    {
     "data": {
      "text/plain": "(555737, 466)"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt = hl.import_plink(bed=f\"{cohort.original_bfile}.bed\",\n",
    "                     bim=f\"{cohort.original_bfile}.bim\",\n",
    "                     fam=f\"{cohort.original_bfile}.fam\",\n",
    "                     reference_genome='GRCh37')\n",
    "mt.count()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rg37 = hl.get_reference('GRCh37')\n",
    "rg38 = hl.get_reference('GRCh38')\n",
    "rg37.add_liftover(\"grch37_to_grch38.over.chain.gz\", rg38)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for cohort in cohorts:\n",
    "    liftover_vcf_file(cohort)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
