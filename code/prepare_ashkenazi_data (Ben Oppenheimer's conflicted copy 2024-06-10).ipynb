{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set-up Functions and Variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "create list of Ashkenazi Samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../ashkenazi_data/EuropeFullyPublic/original_eigenstrat/vdata.ind'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [4], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m reich_samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../ashkenazi_data/EuropeFullyPublic/original_eigenstrat/vdata.ind\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m f\u001B[38;5;241m.\u001B[39mreadlines():\n\u001B[0;32m      4\u001B[0m         sample \u001B[38;5;241m=\u001B[39m line\u001B[38;5;241m.\u001B[39mstrip()\u001B[38;5;241m.\u001B[39msplit()[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:282\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    275\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    276\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    277\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    278\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    279\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    280\u001B[0m     )\n\u001B[1;32m--> 282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m io_open(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../ashkenazi_data/EuropeFullyPublic/original_eigenstrat/vdata.ind'"
     ]
    }
   ],
   "source": [
    "reich_samples = set()\n",
    "with open(\"../ashkenazi_data/EuropeFullyPublic/original_eigenstrat/vdata.ind\") as f:\n",
    "    for line in f.readlines():\n",
    "        sample = line.strip().split()[0]\n",
    "        reich_samples.add(sample)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_samples_in_cohort(fam_file):\n",
    "    samples = dict()\n",
    "    with open(fam_file) as f:\n",
    "        for line in f.readlines():\n",
    "            split_line = line.split()\n",
    "            fam_id = split_line[0]\n",
    "            sample = split_line[1]\n",
    "            samples[sample] = fam_id\n",
    "    return samples\n",
    "\n",
    "\n",
    "def write_samples_to_include(fam_file, cohort_dir):\n",
    "    samples = get_samples_in_cohort(fam_file)\n",
    "    samples_in_cohort = set(samples.keys())\n",
    "\n",
    "    samples_to_consider = all_sample_list - kg_and_hgdp_sample_list\n",
    "\n",
    "    if not os.path.basename(cohort_dir) == \"EuropeFullyPublic\":\n",
    "        samples_to_consider -= reich_samples\n",
    "\n",
    "    samples_to_include = samples_in_cohort.intersection(samples_to_consider)\n",
    "    samples_to_include -= kg_and_hgdp_sample_list\n",
    "\n",
    "    samples_to_include_filename = cohort_dir + \"/samples_to_include.txt\"\n",
    "    samples_output = [[samples[sample], sample] for sample in samples_to_include]\n",
    "    np.savetxt(samples_to_include_filename, samples_output, fmt=\"%s\", delimiter=\"\\t\")\n",
    "    return samples_to_include_filename\n",
    "\n",
    "\n",
    "def liftover_vcf_file(cohort):\n",
    "    input_vcf = cohort.get_suffix_bfile(\"filtered\") + \".vcf\"\n",
    "    mt = hl.import_vcf(input_vcf)\n",
    "    mt = mt.annotate_rows(new_locus=hl.liftover(mt.locus, 'GRCh38', include_strand=True), old_locus=mt.locus)\n",
    "\n",
    "    #save not_lifted vcf info\n",
    "    not_lifted_mt = mt.filter_rows(~hl.is_defined(mt.new_locus) | mt.new_locus.is_negative_strand)\n",
    "    not_lifted_vcf = cohort.get_suffix_bfile(\"not_lifted\") + \".vcf\"\n",
    "    hl.export_vcf(not_lifted_mt, not_lifted_vcf)\n",
    "\n",
    "    lifted_mt = mt.filter_rows(hl.is_defined(mt.new_locus) & ~mt.new_locus.is_negative_strand)\n",
    "    lifted_mt = lifted_mt.key_rows_by(locus=lifted_mt.new_locus.result, alleles=lifted_mt.alleles)\n",
    "    lifted_mt_filename = cohort.get_suffix_bfile(\"lifted_mt\") + \".vcf\"\n",
    "    hl.export_vcf(lifted_mt, lifted_mt_filename)\n",
    "\n",
    "\n",
    "class Cohort:\n",
    "\n",
    "    def __init__(self, original_bfile, is_bfile=True):\n",
    "\n",
    "        self.original_bfile = original_bfile\n",
    "        self.original_bfile_name = os.path.basename(self.original_bfile)\n",
    "\n",
    "        split_dir = self.original_bfile.split(\"/\")\n",
    "        self.dir = \"/\".join(split_dir[0:-2])\n",
    "\n",
    "        if is_bfile:\n",
    "\n",
    "            fam_file = original_bfile + \".fam\"\n",
    "            samples_to_include_filename = write_samples_to_include(fam_file, self.dir)\n",
    "            self.samples_to_include_filename = samples_to_include_filename\n",
    "\n",
    "\n",
    "    def get_suffix_bfile(self, suffix):\n",
    "        corrected_dir = self.dir + \"/\" + suffix\n",
    "\n",
    "        if not os.path.exists(corrected_dir):\n",
    "            os.mkdir(corrected_dir)\n",
    "\n",
    "        corrected_bfile = corrected_dir + \"/\" + self.original_bfile_name + \"_\" + suffix\n",
    "        return corrected_bfile"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "original_bfiles = [\"../ashkenazi_data/caucasus/original_plink/caucasus_paper_data_dbSNP-b131_pos-b37_1KG_strand\",\n",
    "                   \"../ashkenazi_data/EuropeFullyPublic/convertf_plink/vdata\"]\n",
    "cohorts = [Cohort(original_bfile) for original_bfile in original_bfiles]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hg19_fasta = \"../../hg38_reference_data/Homo_sapiens_assembly19.fasta\"\n",
    "for i, cohort in enumerate(cohorts):\n",
    "    print(i)\n",
    "    !plink2 --bfile {cohort.original_bfile} --ref-from-fa $hg19_fasta --make-pgen \\\n",
    "    --keep {cohort.dir}/samples_to_include.txt --out {cohort.get_suffix_bfile(\"fixed_ref\")}\n",
    "    !plink2 --pfile {cohort.get_suffix_bfile(\"fixed_ref\")} --sort-vars --make-pgen --out {cohort.get_suffix_bfile(\"sorted\")}\n",
    "    !plink2 --pfile {cohort.get_suffix_bfile(\"sorted\")} --mind 0.05 --geno 0.05 --export vcf id-paste=iid \\\n",
    "    --out {cohort.get_suffix_bfile(\"filtered\")}\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Liftover Bed Files"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import hail as hl"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hl.init()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rg37 = hl.get_reference('GRCh37')\n",
    "rg38 = hl.get_reference('GRCh38')\n",
    "rg37.add_liftover(\"grch37_to_grch38.over.chain.gz\", rg38)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for cohort in cohorts:\n",
    "    liftover_vcf_file(cohort)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
